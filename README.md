# SegmentaÃ§Ã£o de Imagens com MMsegmentation e ROS2  

<p align="center">
Bem-vindo ao repositÃ³rio de <strong>segmentaÃ§Ã£o semÃ¢ntica de imagens</strong> utilizando a rede neural <strong>SegFormer B2</strong> com <strong>MMSegmentation e ROS2</strong>.  
Este projeto permite o processamento de imagens em tempo real para aplicaÃ§Ãµes em robÃ³tica e veÃ­culos autÃ´nomos.
</p>

<p align="center">
  <a href="#1-introduÃ§Ã£o-e-objetivo-">IntroduÃ§Ã£o e Objetivo</a> Â·
  <a href="#2-ferramentas-utilizadas-">Ferramentas Utilizadas</a> Â·
  <a href="#3-estrutura-do-projeto"->Estrutura do Projeto</a> Â·
  <a href="#4-instalaÃ§Ã£o-e-uso-">InstalaÃ§Ã£o e Uso</a> Â·
  <a href="#5-informaÃ§Ãµes-do-modelo-segformer-b2-">InformaÃ§Ãµes do Modelo</a> Â·
  <a href="#6-dataset-utilizado-">Dataset Utilizado</a> Â·
  <a href="#7-comparaÃ§Ã£o-de-resultados-">ComparaÃ§Ã£o de Resultados</a> Â·
  <a href="#8-como-contribuir-">Como Contribuir</a> Â·
  <a href="#9-licenÃ§a-">LicenÃ§a</a> Â·
  <a href="#10-agradecimentos-">Agradecimentos</a>
</p>




<p align="center">
  <img src="Images/main.png" alt="Arquitetura do SegFormer B2" width="600">
</p>  

---

## 1. IntroduÃ§Ã£o e Objetivo ğŸ“Š

A segmentaÃ§Ã£o semÃ¢ntica em tempo real desempenha um papel **crÃ­tico** na navegaÃ§Ã£o de veÃ­culos autÃ´nomos. O **mÃ³dulo de percepÃ§Ã£o** desses veÃ­culos precisa interpretar rapidamente o ambiente ao seu redor para garantir **seguranÃ§a, eficiÃªncia e tomada de decisÃµes autÃ´noma**.  
  
Em cenÃ¡rios urbanos e rodoviÃ¡rios, um sistema de percepÃ§Ã£o robusto precisa:  

ğŸ”¹ **Identificar e classificar objetos** (pedestres, veÃ­culos, semÃ¡foros, placas de trÃ¢nsito).  
ğŸ”¹ **Delimitar vias, calÃ§adas e obstÃ¡culos** para tomada de decisÃ£o da navegaÃ§Ã£o.  
ğŸ”¹ **Processar informaÃ§Ãµes em tempo real** para evitar colisÃµes e reagir a eventos inesperados.  
ğŸ”¹ **Fornecer dados para mÃ³dulos de planejamento e controle** do veÃ­culo.  

A integraÃ§Ã£o do **SegFormer B2** com **ROS2** possibilita a segmentaÃ§Ã£o eficiente de imagens em **tempo real**, tornando este projeto aplicÃ¡vel a sistemas autÃ´nomos, visÃ£o computacional e robÃ³tica.

### **Objetivos do projeto**:
âœ” **Pipeline para alcanÃ§ar a segmentaÃ§Ã£o semÃ¢ntica em tempo real**.  
âœ” **ImplementaÃ§Ã£o do modelo SegFormer B2** para segmentaÃ§Ã£o semÃ¢ntica.  
âœ” **IntegraÃ§Ã£o com ROS2** para publicaÃ§Ã£o e processamento de imagens.  
âœ” **Suporte para datasets personalizados**.  

---


## 2. Ferramentas Utilizadas ğŸ› 

Este projeto utiliza as seguintes tecnologias:  


- **Linguagem**: Python 
- **Framework de SegmentaÃ§Ã£o**: [MMSegmentation](https://github.com/open-mmlab/mmsegmentation)  
- **Modelo de SegmentaÃ§Ã£o**: SegFormer B2  
- **Middleware de ComunicaÃ§Ã£o**: ROS2 (Robot Operating System 2)  
- **Bibliotecas Auxiliares**:  
   - OpenCV  
   - NumPy  
   - PyTorch  
   - torchvision  
   - mmcv  

---

## 3. Estrutura do Projeto ğŸ“‚


ğŸ“ **Segmentation_MMseg-ROS2-main/**  

â”œâ”€â”€ ğŸ“‚ `config/` â†’ ConfiguraÃ§Ã£o da rede e parÃ¢metros  
â”‚   â”œâ”€â”€ ğŸ“„ `define_net.yaml` â†’ DefiniÃ§Ãµes do modelo  
â”‚  
â”œâ”€â”€ ğŸ“‚ `image_processor/` â†’ Scripts de processamento de imagens  
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ `inference_MMSeg.py` â†’ InferÃªncia com MMSegmentation  
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ `inference_personalized.py` â†’ InferÃªncia personalizada  
â”‚   â”œâ”€â”€ ğŸ“¡ `image_publisher.py` â†’ PublicaÃ§Ã£o de imagens no ROS2  
â”‚   â”œâ”€â”€ ğŸ“¡ `image_subscriber.py` â†’ Assinatura e visualizaÃ§Ã£o das imagens segmentadas  
â”‚  
â”œâ”€â”€ ğŸ“‚ `images_source/` â†’ Imagens de entrada para testes  
â”œâ”€â”€ ğŸ“‚ `masks_images/` â†’ MÃ¡scaras geradas pelo modelo  
â”œâ”€â”€ ğŸ“‚ `resource/` â†’ Modelos treinados e arquivos auxiliares  
â”œâ”€â”€ ğŸ“‚ `test/` â†’ Scripts para testes unitÃ¡rios  
â”‚  
â”œâ”€â”€ ğŸ“„ `setup.py` â†’ Script de instalaÃ§Ã£o  
â”œâ”€â”€ ğŸ“„ `package.xml` â†’ ConfiguraÃ§Ã£o do ROS2  
â”œâ”€â”€ ğŸ“„ `README.md` â†’ DocumentaÃ§Ã£o do projeto  

---

## 4. InstalaÃ§Ã£o e Uso âš™ï¸

### ğŸ”¹ PrÃ©-requisitos  
- Python **3.8+**  
- **ROS2 Galactic** ou mais recente  
  - **CUDA** (caso utilize GPU)  
- DependÃªncias Python:  
   - PyTorch  
   - OpenCV  
   - NumPy  
   - MMCV  
   - MMSegmentation

<br>  

### ğŸš€ Como executar o projeto?  

Para rodar este projeto de segmentaÃ§Ã£o semÃ¢ntica em tempo real utilizando **ROS2 e SegFormer B2**, siga os passos abaixo:

#### 1. **Clone o repositÃ³rio**  
FaÃ§a o download do cÃ³digo-fonte do projeto para sua mÃ¡quina local executando:

```bash
git clone https://github.com/seu-repositorio.git
cd Segmentation_MMseg-ROS2-main
```

#### 2. **Configure o ambiente ROS2**
Antes de executar o projeto, certifique-se de que o ROS2 Galactic (ou versÃ£o mais recente) estÃ¡ instalado e ativado. Execute o seguinte comando:

```bash
source /opt/ros/galactic/setup.bash
```

#### 3. **Compile e execute o workspace ROS2**
Compile os pacotes do ROS2 dentro do diretÃ³rio do projeto:

```bash
colcon build
source install/setup.bash
```

#### 4. **Inicie o publicador de imagens**
O publicador envia imagens para um tÃ³pico ROS2 para serem processadas pelo modelo de segmentaÃ§Ã£o:

```bash
ros2 run image_processor image_publisher.py
```

#### 5. **Rode o assinante para visualizar as imagens segmentadas**
Agora, execute o assinante para receber e exibir as imagens segmentadas:

```bash
ros2 run image_processor image_subscriber.py
```

---

---

## 5. InformaÃ§Ãµes do Modelo **SegFormer B2** ğŸ“Š

O **SegFormer B2** Ã© um modelo avanÃ§ado de segmentaÃ§Ã£o semÃ¢ntica, desenvolvido pela **NVIDIA**, projetado para capturar e interpretar informaÃ§Ãµes visuais com alta precisÃ£o e eficiÃªncia computacional.  

### ğŸ–¥ï¸ **Arquitetura do SegFormer B2**  

<p align="center">
  <img src="Images/segformer_architecture.png" alt="Arquitetura do SegFormer B2" width="600">
</p>  

- **Transformers HierÃ¡rquicos** â†’ Capturam diferentes nÃ­veis de detalhes da imagem, permitindo uma segmentaÃ§Ã£o precisa em mÃºltiplas escalas.  
- **MLP Decoder Leve** â†’ Substitui convoluÃ§Ãµes pesadas por camadas MLP, reduzindo o custo computacional sem comprometer a qualidade da segmentaÃ§Ã£o.  
- **Backbone EfficientNet-like** â†’ Utiliza uma arquitetura otimizada para menor consumo de memÃ³ria e maior velocidade de inferÃªncia.  
- **Independente de ResoluÃ§Ã£o** â†’ Ao contrÃ¡rio de outras abordagens, o SegFormer pode operar em imagens de diferentes tamanhos sem necessidade de reconfiguraÃ§Ã£o.  
- **Suporte a InferÃªncia em Tempo Real** â†’ Otimizado para execuÃ§Ã£o eficiente em **GPUs NVIDIA com TensorRT e CUDA**, garantindo alta taxa de quadros por segundo (FPS).  

### **Vantagens TÃ©cnicas para AplicaÃ§Ãµes em VeÃ­culos AutÃ´nomos**  

- **PrecisÃ£o em Ambientes Complexos** â†’ Permite identificar pedestres, veÃ­culos, semÃ¡foros e obstÃ¡culos com alto grau de confiabilidade.  
- **Baixo Custo Computacional** â†’ Pode ser executado em embarcados e dispositivos com capacidade limitada, como **Jetson Xavier** e **Orin**.  
- **IntegraÃ§Ã£o com ROS2** â†’ Facilita a comunicaÃ§Ã£o entre sensores e mÃ³dulos de tomada de decisÃ£o do veÃ­culo.  
- **GeneralizaÃ§Ã£o para Diferentes CenÃ¡rios** â†’ Pode ser treinado em datasets especÃ­ficos para ambientes urbanos, rodoviÃ¡rios ou industriais.  

Mais detalhes podem ser encontrados na **[documentaÃ§Ã£o oficial do SegFormer](https://github.com/NVlabs/SegFormer)**.  

---

## 6. Dataset Utilizado ğŸ™ï¸

ğŸ“Œ O projeto utiliza por padrÃ£o o dataset **Cityscapes**, que contÃ©m imagens de ruas urbanas anotadas para segmentaÃ§Ã£o.  

ğŸ“Œ **CaracterÃ­sticas do dataset**:  
âœ… **Formato**: PNG com anotaÃ§Ãµes de segmentaÃ§Ã£o.  
âœ… **NÃºmero de Classes**: 19 categorias (carros, pedestres, estradas, edifÃ­cios, etc.).  
âœ… **ResoluÃ§Ã£o**: 1280 x 720 pixels (HD).  

ğŸ“Œ **Usando um dataset personalizado**  
Para utilizar outro dataset, basta alterar os arquivos de configuraÃ§Ã£o e anotaÃ§Ãµes do modelo.

---

## 7. ComparaÃ§Ã£o de Resultados ğŸ“Š

A segmentaÃ§Ã£o semÃ¢ntica em tempo real Ã© um fator **crÃ­tico** para aplicaÃ§Ãµes como **veÃ­culos autÃ´nomos e robÃ³tica**, onde o tempo de resposta e a precisÃ£o sÃ£o essenciais para uma navegaÃ§Ã£o segura. Para avaliar o desempenho dos diferentes modelos, comparamos **FPS de inferÃªncia, tempo mÃ©dio por imagem, consumo computacional (FLOPs) e precisÃ£o**.

Abaixo, apresentamos os **resultados obtidos** na segmentaÃ§Ã£o de imagens utilizando diferentes arquiteturas:  

---

### ğŸ–¼ï¸ **Exemplo de saÃ­da do modelo**  

| ğŸ“· Entrada |  ğŸ¨ Ground Truth | ğŸ¨ SegmentaÃ§Ã£o - SegFormer B2 | ğŸ¨ SegmentaÃ§Ã£o - DeepLabV3 |
|-----------|-----------------------------|--------------------------|----------------------|
| ![Input Image](Images/img.png) | ![SegFormer](Images/groundT.png) | ![DeepLabV3](Images/Segformer.png) | ![PSPNet](Images/dlv3.png) |

ğŸ“Œ **ObservaÃ§Ã£o:** As diferenÃ§as entre os modelos podem ser notadas na suavizaÃ§Ã£o dos contornos, detalhamento das bordas e segmentaÃ§Ã£o precisa de classes menores.

---

### ğŸ“ˆ **Tabela de ComparaÃ§Ã£o entre Modelos**  

| **Modelo** | **ConfiguraÃ§Ã£o** | **FPS (InferÃªncia)** | **Tempo por Imagem (seg)** | **FLOPs (TeraOps)** | **NÃºmero de ParÃ¢metros (MilhÃµes)** | **PrecisÃ£o (%)** |
|------------|-----------------|----------------------|--------------------------|----------------------|----------------------------------|------------------|
| **SegFormer B2** | `segformer_mit-b2_8xb1-160k_cityscapes-1024x1024` | **6.70 img/s** | 0.149 seg/img | 0.123T | 24.7M | **87.8%** |
| **DeepLabV3 R50-D8** | `deeplabv3_r50-d8_4xb2-40k_cityscapes-512x1024` | 3.18 img/s | 0.314 seg/img | 0.949T | 65.7M | 85.7% |
| **PSPNet R50-D8** | `pspnet_r50-d8_4xb2-40k_cityscapes-512x1024` | 6.42 img/s | 0.156 seg/img | 0.628T | 46.6M | 82.3% |
| **FCN R50-D8** | `fcn_r50-d8_4xb2-40k_cityscapes-512x1024` | 6.30 img/s | 0.159 seg/img | 0.696T | 47.1M | 81.3% |
| **FCN R18-D8** | `fcn_r18-d8_4xb2-80k_cityscapes-512x1024` | **28.93 img/s** | 0.035 seg/img | 0.195T | 12.6M | 77.8% |
| **FPN R50** | `fpn_r50_4xb2-80k_cityscapes-512x1024` | **24.85 img/s** | 0.040 seg/img | **0.160T** | 28.4M | 79.7% |

---

### ğŸ“Œ **AnÃ¡lise dos Resultados**  

ğŸ“Œ **SegFormer B2** apresenta **o melhor equilÃ­brio entre velocidade e precisÃ£o**, tornando-se ideal para aplicaÃ§Ãµes em tempo real, como veÃ­culos autÃ´nomos.  

ğŸ“Œ **FCN R18-D8 e FPN R50** sÃ£o **mais rÃ¡pidos**, mas sacrificam a precisÃ£o, sendo mais adequados para sistemas com restriÃ§Ãµes computacionais.  

ğŸ“Œ **DeepLabV3 R50-D8** oferece uma boa precisÃ£o, mas tem um **alto custo computacional** e um FPS reduzido, o que pode comprometer sua aplicaÃ§Ã£o em tempo real.  

ğŸ“Œ **PSPNet R50-D8** e **FCN R50-D8** possuem **desempenho intermediÃ¡rio**, sendo opÃ§Ãµes equilibradas para tarefas que exigem boa segmentaÃ§Ã£o sem sacrificar tanto a eficiÃªncia.  

ğŸ’¡ **ConclusÃ£o:** O **SegFormer B2** se destaca para aplicaÃ§Ãµes onde **tempo de resposta e precisÃ£o sÃ£o cruciais**, como veÃ­culos autÃ´nomos. Modelos mais leves como **FCN R18-D8** podem ser usados para sistemas embarcados com menos poder computacional.  

---

## 8. Como Contribuir? ğŸ¤

ContribuiÃ§Ãµes sÃ£o sempre bem-vindas!

ğŸ’¡ **Se tiver dÃºvidas, sinta-se Ã  vontade para abrir uma "Issue" e discutir sua ideia antes de contribuir!** ğŸš€  

---

## 9. LicenÃ§a ğŸ“œ

Este projeto Ã© distribuÃ­do sob a **LicenÃ§a MIT**, permitindo uso, modificaÃ§Ã£o e distribuiÃ§Ã£o livremente, desde que os devidos crÃ©ditos sejam mantidos.  

ğŸ“„ Consulte o arquivo `LICENSE` para mais detalhes sobre os termos da licenÃ§a.  

---

## 10. Agradecimentos ğŸ™

GostarÃ­amos de expressar nosso profundo agradecimento ao **LaboratÃ³rio de RobÃ³tica MÃ³vel (LRM) do ICMC-USP** pelo suporte e infraestrutura fornecidos para o desenvolvimento deste projeto.  

